{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13665,"status":"ok","timestamp":1730762121977,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"yrn_VB8L0CNl","outputId":"2efceeb2-9142-4861-cd7f-65ecaf1dd7ed"},"outputs":[],"source":["import os\n","import random\n","import yaml\n","import csv\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import wandb\n","import shutil\n","import gc\n","import timm\n","\n","from functools import partial\n","from torchsummaryX import summary\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","from torchvision.transforms import functional as F\n","import torchvision.transforms.functional as TF\n","from tqdm import tqdm\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Configurations"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["config = {\n","    \"model\" : \"seresnext\",\n","\n","    ###### Dataset -----------------------------------------------------------------\n","    \"dataset_root\" : \"./data/VOC_PCB\",\n","    \"num_workers\" : 12,\n","    \"batch_size\" : 256,\n","\n","    ###### DataAugment ---------------------------------------------------------------\n","\n","    ###### Loss function -------------------------------------------------------------\n","    \"loss\" : \"crossEntropy\",\n","    \"ce_smoothing_factor\" : 0.2,\n","\n","    ###### Scheduler Parameters ------------------------------------------------------\n","    \"scheduler\" : \"ReduceLR\",  # ['ReduceLR', 'CosineAnnealing']\n","    \"learning_rate\" : 1e-3,\n","    \"reducelr_factor\" : 0.5,\n","    \"reducelr_patience\" : 3,\n","    \"reducelr_threshold\" : 1e-3, \n","    \"reducelr_minlr\" : 1e-6,\n","\n","    ###### Optimizer Parameters ------------------------------------------------------\n","    \"optimizer\" : \"AdamW\", # Adam, AdamW, SGD\n","    \"weight_decay\" : 0.01,\n","\n","\n","    ###### Training Parameters -------------------------------------------------------\n","    \"use_wandb\" : True,\n","    \"dropout_rate\" : 0.2,\n","    \"epochs\" : 100,\n","}"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["config_path = \"./config.yaml\"\n","with open(config_path, \"w\") as file:\n","    yaml.dump(config, file, default_flow_style=False, sort_keys=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["DEFECT_CLASSES = {\n","            \"mouse_bite\": 0,\n","            \"short\": 1,\n","            \"open_circuit\": 2,\n","            \"spur\": 3,\n","            \"missing_hole\": 4,\n","            \"spurious_copper\": 5,\n","        }"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730762287927,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"aKLwTtTB0v8E"},"outputs":[],"source":["device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRGIluA8lpB4"},"outputs":[],"source":["def count_images_for_splits(root):\n","    split_files = ['train', 'trainval', 'val', 'test']\n","    image_counts = {}\n","\n","    for split in split_files:\n","        file_path = os.path.join(root, \"ImageSets\", \"Main\", f\"{split}.txt\")\n","        if os.path.exists(file_path):\n","            with open(file_path, 'r') as f:\n","                image_ids = f.read().splitlines()\n","                image_counts[split] = len(image_ids)\n","        else:\n","            image_counts[split] = 0  # If the file doesn't exist, set count to 0\n","\n","    return image_counts\n","\n","image_counts = count_images_for_splits(config[\"dataset_root\"])\n","# Display the counts\n","for split, count in image_counts.items():\n","    print(f\"Number of images in {split}: {count}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1042,"status":"ok","timestamp":1730763038383,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"_sZ5__YY0OQy"},"outputs":[],"source":["class PCBDataset(Dataset):\n","    def __init__(self, root, transforms=None, split=\"train\"):\n","        self.root = root\n","        self.transforms = transforms\n","        self.split = split\n","\n","        self.img_dir = os.path.join(root, \"JPEGImages\")\n","        self.ann_dir = os.path.join(root, \"Annotations\")\n","\n","        # Load image IDs for the specified split\n","        img_ids = []\n","        if split == \"train\":\n","            with open(os.path.join(root, \"ImageSets\", \"Main\", \"train.txt\")) as f:\n","                img_ids += f.read().splitlines()\n","            with open(os.path.join(root, \"ImageSets\", \"Main\", \"trainval.txt\")) as f:\n","                img_ids += f.read().splitlines()\n","            self.img_ids = list(set(img_ids))\n","        else:\n","            with open(os.path.join(root, \"ImageSets\", \"Main\", f\"{split}.txt\")) as f:\n","                self.img_ids = f.read().splitlines()\n","\n","        # Define defect classes, starting from 0\n","        self.defect_classes = DEFECT_CLASSES\n","\n","    def __len__(self):\n","        return len(self.img_ids)\n","\n","    def __getitem__(self, idx):\n","        img_id = self.img_ids[idx]\n","        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n","        ann_path = os.path.join(self.ann_dir, f\"{img_id}.xml\")\n","\n","        # Load image\n","        img = Image.open(img_path).convert(\"RGB\")\n","\n","        # Parse XML annotation file to get defect labels\n","        tree = ET.parse(ann_path)\n","        root = tree.getroot()\n","\n","        labels = []\n","\n","        # Collect all defect labels in the image\n","        for obj in root.findall(\"object\"):\n","            defect_name = obj.find(\"name\").text\n","            if defect_name in self.defect_classes:\n","                labels.append(self.defect_classes[defect_name])\n","            else:\n","                raise RuntimeError(f\"Unexpected defect type {defect_name}\")\n","\n","        # Determine the most common defect label as the classification label\n","        if labels:\n","            label = max(set(labels), key=labels.count)  # Most common label in the image\n","        else:\n","            label = 0  # Assign a default label if no defect is found\n","\n","        # Apply transforms if specified\n","        if self.transforms:\n","            img = self.transforms(img)\n","\n","        return img, label"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Data Augmentation"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1027,"status":"ok","timestamp":1730763479885,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"0O8_l-0Q10lN"},"outputs":[],"source":["# Data transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((224, 224)),  # ResNet-50 expects 224x224 input\n","    #transforms.Resize((600, 600)),  this is the original image resolution\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Standard normalization for ResNet\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 Data Loader"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730763480241,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"TluELfUB111f"},"outputs":[],"source":["# Load datasets for train, val, and test splits\n","train_dataset = PCBDataset(root=config[\"dataset_root\"], transforms=transform, split=\"train\")\n","val_dataset = PCBDataset(root=config[\"dataset_root\"], transforms=transform, split=\"val\")\n","test_dataset = PCBDataset(root=config[\"dataset_root\"], transforms=transform, split=\"test\")\n","\n","# Define DataLoaders without custom collate_fn\n","train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1730764207054,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"EU2ur7fTlerh","outputId":"22bdb230-ac9c-40d6-8554-d0821666c197"},"outputs":[],"source":["print(f\"Number of images in train dataset: {len(train_dataset)}\")\n","print(f\"Number of images in validation dataset: {len(val_dataset)}\")\n","print(f\"Number of images in test dataset: {len(test_dataset)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## 3.4 Data preview"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load a subset of the training dataset for inspection\n","subset_dataset = torch.utils.data.Subset(train_dataset, range(10))\n","subset_loader = DataLoader(subset_dataset, batch_size=1)\n","\n","# Iterate through the subset and print out sample information\n","for img, label in subset_loader:\n","    print(\"Sample loaded successfully.\")\n","    print(\"Label:\", label.item())\n","    break  # Only check the first sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19vTXJYNxmA2SwP4Pf_1Sbc0Q0bPYP4yh"},"executionInfo":{"elapsed":58272,"status":"ok","timestamp":1730763540660,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":300},"id":"PaTB2M45n_4b","outputId":"fc7fc9db-5a9f-4adc-86c8-15ef5a6c5a83"},"outputs":[],"source":["# Updated label mapping to match the zero-based indexing\n","label_map = {\n","    0: \"Mouse Bites\",\n","    1: \"Shorts\",\n","    2: \"Open Circuits\",\n","    3: \"Spurs\",\n","    4: \"Missing Holes\",\n","    5: \"Spurious Coppers\"\n","}\n","\n","# Set grid dimensions\n","rows, cols = 5, 5  # Display a 5x5 grid of images\n","\n","# Initialize plot\n","fig, ax = plt.subplots(rows, cols, figsize=(15, 15))\n","plt.subplots_adjust(hspace=0.5, wspace=0.3)  # Adjust spacing for label display\n","\n","# Load a batch of samples (images and labels)\n","data_loader = DataLoader(train_dataset, batch_size=rows * cols, shuffle=True)\n","images, labels = next(iter(data_loader))\n","\n","# Loop over the samples in the batch and plot each with labels\n","for idx in range(rows * cols):\n","    i, j = divmod(idx, cols)  # Determine grid position\n","    image = images[idx]\n","    label = labels[idx].item()\n","\n","    # Convert to PIL image for proper display\n","    img = TF.to_pil_image(image)\n","    ax[i, j].imshow(img)\n","    ax[i, j].axis('off')  # Remove axes for a cleaner look\n","\n","    # Display the human-readable label below each image\n","    ax[i, j].set_title(label_map.get(label, \"Unknown\"), fontsize=10, color=\"blue\")\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Model"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class ResNetClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        # Load pretrained ResNet-50 model\n","        self.backbone = timm.create_model(\"resnet50\", pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["class EfficientNetClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        # Load pretrained ResNet-50 model\n","        self.backbone = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class ViTClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        # Load pretrained ResNet-50 model\n","        self.backbone = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from typing import Any, Dict, List, Optional, Tuple, Type, Union\n","\n","from timm.layers import DropBlock2d, DropPath, AvgPool2dSame, BlurPool2d, LayerType, create_attn, \\\n","    get_attn, get_act_layer, get_norm_layer, create_classifier, create_aa, to_ntuple"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","            self,\n","            inplanes: int,\n","            planes: int,\n","            stride: int = 1,\n","            downsample: Optional[nn.Module] = None,\n","            cardinality: int = 1,\n","            base_width: int = 64,\n","            reduce_first: int = 1,\n","            dilation: int = 1,\n","            first_dilation: Optional[int] = None,\n","            act_layer: Type[nn.Module] = nn.ReLU,\n","            norm_layer: Type[nn.Module] = nn.BatchNorm2d,\n","            attn_layer: Optional[Type[nn.Module]] = None,\n","            aa_layer: Optional[Type[nn.Module]] = None,\n","            drop_block: Optional[Type[nn.Module]] = None,\n","            drop_path: Optional[nn.Module] = None,\n","    ):\n","        \"\"\"\n","        Args:\n","            inplanes: Input channel dimensionality.\n","            planes: Used to determine output channel dimensionalities.\n","            stride: Stride used in convolution layers.\n","            downsample: Optional downsample layer for residual path.\n","            cardinality: Number of convolution groups.\n","            base_width: Base width used to determine output channel dimensionality.\n","            reduce_first: Reduction factor for first convolution output width of residual blocks.\n","            dilation: Dilation rate for convolution layers.\n","            first_dilation: Dilation rate for first convolution layer.\n","            act_layer: Activation layer.\n","            norm_layer: Normalization layer.\n","            attn_layer: Attention layer.\n","            aa_layer: Anti-aliasing layer.\n","            drop_block: Class for DropBlock layer.\n","            drop_path: Optional DropPath layer.\n","        \"\"\"\n","        super(Bottleneck, self).__init__()\n","\n","        width = int(math.floor(planes * (base_width / 64)) * cardinality)\n","        first_planes = width // reduce_first\n","        outplanes = planes * self.expansion\n","        first_dilation = first_dilation or dilation\n","        use_aa = aa_layer is not None and (stride == 2 or first_dilation != dilation)\n","\n","        self.conv1 = nn.Conv2d(inplanes, first_planes, kernel_size=1, bias=False)\n","        self.bn1 = norm_layer(first_planes)\n","        self.act1 = act_layer(inplace=True)\n","\n","        self.conv2 = nn.Conv2d(\n","            first_planes, width, kernel_size=3, stride=1 if use_aa else stride,\n","            padding=first_dilation, dilation=first_dilation, groups=cardinality, bias=False)\n","        self.bn2 = norm_layer(width)\n","        self.drop_block = drop_block() if drop_block is not None else nn.Identity()\n","        self.act2 = act_layer(inplace=True)\n","        self.aa = create_aa(aa_layer, channels=width, stride=stride, enable=use_aa)\n","\n","        self.conv3 = nn.Conv2d(width, outplanes, kernel_size=1, bias=False)\n","        self.bn3 = norm_layer(outplanes)\n","\n","        self.se = create_attn(attn_layer, outplanes)\n","\n","        self.act3 = act_layer(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","        self.dilation = dilation\n","        self.drop_path = drop_path\n","\n","    def zero_init_last(self):\n","        if getattr(self.bn3, 'weight', None) is not None:\n","            nn.init.zeros_(self.bn3.weight)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        shortcut = x\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.act1(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.drop_block(x)\n","        x = self.act2(x)\n","        x = self.aa(x)\n","\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","\n","        if self.se is not None:\n","            x = self.se(x)\n","\n","        if self.drop_path is not None:\n","            x = self.drop_path(x)\n","\n","        if self.downsample is not None:\n","            shortcut = self.downsample(shortcut)\n","        x += shortcut\n","        x = self.act3(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def get_padding(kernel_size: int, stride: int, dilation: int = 1) -> int:\n","    padding = ((stride - 1) + dilation * (kernel_size - 1)) // 2\n","    return padding\n","\n","def downsample_conv(\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: int,\n","        stride: int = 1,\n","        dilation: int = 1,\n","        first_dilation: Optional[int] = None,\n","        norm_layer: Optional[Type[nn.Module]] = None,\n",") -> nn.Module:\n","    norm_layer = norm_layer or nn.BatchNorm2d\n","    kernel_size = 1 if stride == 1 and dilation == 1 else kernel_size\n","    first_dilation = (first_dilation or dilation) if kernel_size > 1 else 1\n","    p = get_padding(kernel_size, stride, first_dilation)\n","\n","    return nn.Sequential(*[\n","        nn.Conv2d(\n","            in_channels, out_channels, kernel_size, stride=stride, padding=p, dilation=first_dilation, bias=False),\n","        norm_layer(out_channels)\n","    ])\n","\n","\n","def downsample_avg(\n","        in_channels: int,\n","        out_channels: int,\n","        kernel_size: int,\n","        stride: int = 1,\n","        dilation: int = 1,\n","        first_dilation: Optional[int] = None,\n","        norm_layer: Optional[Type[nn.Module]] = None,\n",") -> nn.Module:\n","    norm_layer = norm_layer or nn.BatchNorm2d\n","    avg_stride = stride if dilation == 1 else 1\n","    if stride == 1 and dilation == 1:\n","        pool = nn.Identity()\n","    else:\n","        avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d\n","        pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)\n","\n","    return nn.Sequential(*[\n","        pool,\n","        nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n","        norm_layer(out_channels)\n","    ])\n","\n","\n","def drop_blocks(drop_prob: float = 0.):\n","    return [\n","        None, None,\n","        partial(DropBlock2d, drop_prob=drop_prob, block_size=5, gamma_scale=0.25) if drop_prob else None,\n","        partial(DropBlock2d, drop_prob=drop_prob, block_size=3, gamma_scale=1.00) if drop_prob else None]\n","\n","\n","def make_blocks(\n","        block_fns: Bottleneck,\n","        channels: Tuple[int, ...],\n","        block_repeats: Tuple[int, ...],\n","        inplanes: int,\n","        reduce_first: int = 1,\n","        output_stride: int = 32,\n","        down_kernel_size: int = 1,\n","        avg_down: bool = False,\n","        drop_block_rate: float = 0.,\n","        drop_path_rate: float = 0.,\n","        **kwargs,\n",") -> Tuple[List[Tuple[str, nn.Module]], List[Dict[str, Any]]]:\n","    stages = []\n","    feature_info = []\n","    net_num_blocks = sum(block_repeats)\n","    net_block_idx = 0\n","    net_stride = 4\n","    dilation = prev_dilation = 1\n","    for stage_idx, (block_fn, planes, num_blocks, db) in enumerate(zip(block_fns, channels, block_repeats, drop_blocks(drop_block_rate))):\n","        stage_name = f'layer{stage_idx + 1}'  # never liked this name, but weight compat requires it\n","        stride = 1 if stage_idx == 0 else 2\n","        if net_stride >= output_stride:\n","            dilation *= stride\n","            stride = 1\n","        else:\n","            net_stride *= stride\n","\n","        downsample = None\n","        if stride != 1 or inplanes != planes * block_fn.expansion:\n","            down_kwargs = dict(\n","                in_channels=inplanes,\n","                out_channels=planes * block_fn.expansion,\n","                kernel_size=down_kernel_size,\n","                stride=stride,\n","                dilation=dilation,\n","                first_dilation=prev_dilation,\n","                norm_layer=kwargs.get('norm_layer'),\n","            )\n","            downsample = downsample_avg(**down_kwargs) if avg_down else downsample_conv(**down_kwargs)\n","\n","        block_kwargs = dict(reduce_first=reduce_first, dilation=dilation, drop_block=db, **kwargs)\n","        blocks = []\n","        for block_idx in range(num_blocks):\n","            downsample = downsample if block_idx == 0 else None\n","            stride = stride if block_idx == 0 else 1\n","            block_dpr = drop_path_rate * net_block_idx / (net_num_blocks - 1)  # stochastic depth linear decay rule\n","            blocks.append(block_fn(\n","                inplanes,\n","                planes,\n","                stride,\n","                downsample,\n","                first_dilation=prev_dilation,\n","                drop_path=DropPath(block_dpr) if block_dpr > 0. else None,\n","                **block_kwargs,\n","            ))\n","            prev_dilation = dilation\n","            inplanes = planes * block_fn.expansion\n","            net_block_idx += 1\n","\n","        stages.append((stage_name, nn.Sequential(*blocks)))\n","        feature_info.append(dict(num_chs=inplanes, reduction=net_stride, module=stage_name))\n","\n","    return stages, feature_info"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class SEResNext(nn.Module):\n","    def __init__(\n","            self,\n","            block: Bottleneck,\n","            layers: Tuple[int, ...],\n","            num_classes: int = 1000,\n","            in_chans: int = 3,\n","            output_stride: int = 32,\n","            cardinality: int = 1,\n","            base_width: int = 64,\n","            block_reduce_first: int = 1,\n","            down_kernel_size: int = 1,\n","            channels: Optional[Tuple[int, ...]] = (64, 128, 256, 512),\n","            drop_rate: float = 0.0,\n","            zero_init_last: bool = True,\n","            block_args: Optional[Dict[str, Any]] = None,\n","    ):\n","        super(SEResNext, self).__init__()\n","        block_args = block_args or dict()\n","        assert output_stride in (8, 16, 32)\n","        self.num_classes = num_classes\n","        self.drop_rate = drop_rate\n","        self.grad_checkpointing = False\n","        \n","        stem_width: int = 64\n","        stem_type: str = ''\n","\n","        act_layer = nn.ReLU\n","        norm_layer = nn.BatchNorm2d\n","\n","        # Stem\n","        deep_stem = 'deep' in stem_type\n","        inplanes = stem_width * 2 if deep_stem else 64\n","        if deep_stem:\n","            stem_chs = (stem_width, stem_width)\n","            if 'tiered' in stem_type:\n","                stem_chs = (3 * (stem_width // 4), stem_width)\n","            self.conv1 = nn.Sequential(*[\n","                nn.Conv2d(in_chans, stem_chs[0], 3, stride=2, padding=1, bias=False),\n","                norm_layer(stem_chs[0]),\n","                act_layer(inplace=True),\n","                nn.Conv2d(stem_chs[0], stem_chs[1], 3, stride=1, padding=1, bias=False),\n","                norm_layer(stem_chs[1]),\n","                act_layer(inplace=True),\n","                nn.Conv2d(stem_chs[1], inplanes, 3, stride=1, padding=1, bias=False)])\n","        else:\n","            self.conv1 = nn.Conv2d(in_chans, inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = norm_layer(inplanes)\n","        self.act1 = act_layer(inplace=True)\n","        self.feature_info = [dict(num_chs=inplanes, reduction=2, module='act1')]\n","\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # Feature Blocks\n","        block_fns = to_ntuple(len(channels))(block)\n","        stage_modules, stage_feature_info = make_blocks(\n","            block_fns,\n","            channels,\n","            layers,\n","            inplanes,\n","            cardinality=cardinality,\n","            base_width=base_width,\n","            output_stride=output_stride,\n","            reduce_first=block_reduce_first,\n","            avg_down=False,\n","            down_kernel_size=down_kernel_size,\n","            act_layer=act_layer,\n","            norm_layer=norm_layer,\n","            aa_layer=None,\n","            drop_block_rate=0.,\n","            drop_path_rate=0.,\n","            **block_args,\n","        )\n","        for stage in stage_modules:\n","            self.add_module(*stage)  # layer1, layer2, etc\n","        self.feature_info.extend(stage_feature_info)\n","\n","        # Head (Pooling and Classifier)\n","        self.num_features = self.head_hidden_size = channels[-1] * block_fns[-1].expansion\n","        self.global_pool, self.fc = create_classifier(self.num_features, self.num_classes, pool_type='avg')\n","\n","        self.init_weights(zero_init_last=zero_init_last)\n","\n","    def init_weights(self, zero_init_last: bool = True):\n","        for n, m in self.named_modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        if zero_init_last:\n","            for m in self.modules():\n","                if hasattr(m, 'zero_init_last'):\n","                    m.zero_init_last()\n","\n","    def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.act1(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        return x\n","\n","    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:\n","        x = self.global_pool(x)\n","        if self.drop_rate:\n","            x = F.dropout(x, p=float(self.drop_rate), training=self.training)\n","        return x if pre_logits else self.fc(x)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.forward_features(x)\n","        x = self.forward_head(x)\n","        return x"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["class SEResNextClassifier(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        # Load pretrained ResNet-50 model\n","        self.backbone = timm.create_model(\"seresnext101_32x8d\", pretrained=True, num_classes=num_classes)\n","\n","    def forward(self, x):\n","        return self.backbone(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Specify the number of classes\n","num_classes = len(DEFECT_CLASSES)\n","\n","if config[\"model\"] == \"resnet\":\n","    model = ResNetClassifier(num_classes)\n","elif config[\"model\"] == \"efficientnet\":\n","    model = EfficientNetClassifier(num_classes)\n","elif config[\"model\"] == \"vit\":\n","    model = ViTClassifier(num_classes)\n","elif config[\"model\"] == \"seresnext\":\n","    model_args = dict(\n","        block=Bottleneck, \n","        layers=(3, 4, 23, 3), \n","        cardinality=32, \n","        base_width=4,\n","        block_args=dict(attn_layer='se'))\n","    model = SEResNext(**model_args, num_classes=num_classes)\n","    model = SEResNextClassifier(num_classes)\n","\n","# Move the model to GPU if available\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for x, y in DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True):\n","    # Print the model structure\n","    summary(model, x.to(device))\n","    break"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Uncomment the line for saving the scheduler save dict if you are using a scheduler\n","def save_model(model, optimizer, scheduler, metrics, epoch, path):\n","    torch.save(\n","        {'model_state_dict'         : model.state_dict(),\n","         'optimizer_state_dict'     : optimizer.state_dict(),\n","         'scheduler_state_dict'     : scheduler.state_dict(),\n","         'metric'                   : metrics,\n","         'epoch'                    : epoch},\n","         path)\n","\n","\n","def load_model(model, optimizer=None, scheduler=None, path='./checkpoint.pth'):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    if optimizer is not None:\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    else:\n","        optimizer = None\n","    if scheduler is not None:\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","    else:\n","        scheduler = None\n","    epoch = checkpoint['epoch']\n","    metrics = checkpoint['metric']\n","    return model, optimizer, scheduler, epoch, metrics"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Training Components"]},{"cell_type":"markdown","metadata":{},"source":["## 5.1 Loss Function"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["if config[\"loss\"] == \"crossEntropy\":\n","    classification_criterion = nn.CrossEntropyLoss(label_smoothing=config[\"ce_smoothing_factor\"])\n","else:\n","    raise NotImplementedError"]},{"cell_type":"markdown","metadata":{},"source":["## 5.2 Optimizer"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["if config[\"optimizer\"] == \"AdamW\":\n","    # AdamW\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n","else:\n","    raise NotImplementedError"]},{"cell_type":"markdown","metadata":{},"source":["## 5.3 Learning Rate Scheduler"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1730480336603,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":240},"id":"IuHbsyjU18Oi","outputId":"0a89e1ca-e979-4377-92a5-1ac4cd5f84ac"},"outputs":[],"source":["if config[\"scheduler\"] == \"ReduceLR\":\n","    # ReduceLROnPlateau scheduler\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, \n","        mode='min', \n","        factor=config[\"reducelr_factor\"], \n","        patience=config[\"reducelr_patience\"], \n","        threshold=config[\"reducelr_threshold\"], \n","        min_lr=config[\"reducelr_minlr\"])\n","else:\n","    raise NotImplementedError"]},{"cell_type":"markdown","metadata":{},"source":["## 5.4 wandb"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["USE_WANDB = config['use_wandb']\n","RESUME_LOGGING = False\n","\n","run_name = \"{}\".format(\n","        config[\"model\"],\n","    )\n","\n","expt_root = os.path.join(os.getcwd(), \"exp\", run_name)\n","os.makedirs(expt_root, exist_ok=True)\n","\n","if USE_WANDB:\n","    wandb.login(key=\"\", relogin=True)\n","\n","    if RESUME_LOGGING:\n","        resume_id = \"test\"\n","        run = wandb.init(\n","            id     = resume_id,        ### Insert specific run id here if you want to resume a previous run\n","            resume = True,          ### You need this to resume previous runs, but comment out reinit=True when using this\n","            project = \"project\",  ### Project should be created in your wandb account\n","        )\n","\n","    else:\n","        run = wandb.init(\n","            name    = run_name,     ### Wandb creates random run names if you skip this field, we recommend you give useful names\n","            reinit  = True,         ### Allows reinitalizing runs when you re-run this cell\n","            project = \"project\",  ### Project should be created in your wandb account\n","            config  = config        ### Wandb Config for your run\n","        )\n","\n","        ### Save your model architecture as a string with str(model)\n","        model_arch  = str(model)\n","        ### Save it in a txt file\n","        model_path = os.path.join(expt_root, \"model_arch.txt\")\n","        arch_file   = open(model_path, \"w\")\n","        file_write  = arch_file.write(model_arch)\n","        arch_file.close()\n","\n","        ### Log it in your wandb run with wandb.sav\n","\n","\n","### Create a local directory with all the checkpoints\n","shutil.copy(os.path.join(os.getcwd(), config_path), os.path.join(expt_root, 'config.yaml'))\n","e                   = 0\n","best_loss           = 1.2\n","best_perplexity     = 23.0\n","best_dist = 60\n","RESUME_LOGGING = False\n","checkpoint_root = os.path.join(expt_root, 'checkpoints')\n","text_root       = os.path.join(expt_root, 'out_text')\n","os.makedirs(checkpoint_root, exist_ok=True)\n","os.makedirs(text_root,       exist_ok=True)\n","checkpoint_best_loss_model_filename     = 'checkpoint-best-loss-modelfull.pth'\n","checkpoint_last_epoch_filename          = 'checkpoint-epochfull-'\n","best_loss_model_path                    = os.path.join(checkpoint_root, checkpoint_best_loss_model_filename)\n","\n","if USE_WANDB:\n","    wandb.watch(model, log=\"all\")\n","    wandb.save(config_path)\n","\n","if RESUME_LOGGING:\n","    # change if you want to load best test model accordingly\n","    checkpoint = torch.load(wandb.restore(checkpoint_best_loss_model_filename, run_path=\"\"+resume_id).name)\n","\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    e = checkpoint['epoch']\n","\n","    print(\"Resuming from epoch {}\".format(e+1))\n","    print(\"Epochs left: \", config['epochs']-e)\n","    print(\"Optimizer: \\n\", optimizer)\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# 6. Functions"]},{"cell_type":"markdown","metadata":{},"source":["## 6.1 Metrics"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["class metric_accuracy:\n","    def __init__(self):\n","        self.total = 0\n","        self.total_correct = 0\n","\n","        self.correct_by_class = [0] * len(DEFECT_CLASSES)\n","        self.total_by_class = [0] * len(DEFECT_CLASSES)\n","\n","        self.accuracy = 0\n","        self.accuracy_by_class = [0] * len(DEFECT_CLASSES)\n","\n","    def update(self, outputs, labels):\n","        self.total += outputs.shape[0]\n","\n","        # Calculate overall correct predictions\n","        preds = outputs.argmax(dim=1)\n","        self.total_correct += (preds == labels).sum().item()\n","\n","        num_classes = len(DEFECT_CLASSES)\n","        # Calculate per-class correct predictions\n","        for label in range(num_classes):\n","            self.correct_by_class[label] += ((preds == label) & (labels == label)).sum().item()\n","            self.total_by_class[label] += (labels == label).sum().item()\n","\n","        self.accuracy = 100 * self.total_correct / self.total\n","\n","        # Calculate per-class accuracy\n","        for i in range(num_classes):\n","            class_correct = self.correct_by_class[i]\n","            class_total = self.total_by_class[i] if self.total_by_class[i] != 0 else 1\n","            self.accuracy_by_class[i] = class_correct / class_total\n","    \n","    def get(self):\n","        return self.accuracy, self.accuracy_by_class"]},{"cell_type":"markdown","metadata":{},"source":["## 6.1 Training"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"o04mUli6dLf6"},"outputs":[],"source":["# Structures to track metrics over epochs\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","class_names = [\"Mouse Bites\", \"Shorts\", \"Open Circuits\", \"Spurs\", \"Missing Holes\", \"Spurious Coppers\"]\n","\n","def train_one_epoch(model, train_loader, optimizer, criterion, device):\n","    model.train()\n","    running_loss = 0.0\n","\n","    # init metrics\n","    m_acc = metric_accuracy()\n","\n","    # Initialize progress bar\n","    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n","\n","    for imgs, labels in progress_bar:\n","        imgs, labels = imgs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss\n","        running_loss += loss.item()\n","\n","        m_acc.update(outputs, labels)\n","\n","        # Update progress bar with overall loss and accuracy\n","        progress_bar.set_postfix(loss=loss.item(), accuracy=f\"{m_acc.get()[0]:.2f}%\")\n","\n","    # Final calculations for epoch loss and accuracy\n","    epoch_loss = running_loss / len(train_loader)\n","\n","    return epoch_loss, *m_acc.get()"]},{"cell_type":"markdown","metadata":{},"source":["## 6.2 Validation"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def evaluate(model, val_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","\n","    # Metrics\n","    m_acc = metric_accuracy()\n","\n","    with torch.no_grad():\n","        for imgs, labels in val_loader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            # Accumulate loss\n","            running_loss += loss.item()\n","\n","            m_acc.update(outputs, labels)\n","\n","    # Final calculations for validation loss and accuracy\n","    val_loss = running_loss / len(val_loader)\n","    overall_accuracy, accuracy_by_class = m_acc.get()\n","\n","    return val_loss, overall_accuracy, accuracy_by_class"]},{"cell_type":"markdown","metadata":{},"source":["# 7. Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3730319,"status":"error","timestamp":1730484066917,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":240},"id":"Xhicm3ve2Bh3","outputId":"c4befc1a-f932-4b7f-b640-a97043a29edc"},"outputs":[],"source":["# Tracking metrics for plotting\n","train_class_accuracies = {label: [] for label in class_names}\n","val_class_accuracies = {label: [] for label in class_names}\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","epochs = config[\"epochs\"]\n","\n","for epoch in range(e, epochs):\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    # Train for one epoch\n","    epoch_loss, train_accuracy, train_accuracy_by_class = train_one_epoch(model, train_loader, optimizer, classification_criterion, device)\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(train_accuracy)\n","    for i, acc in enumerate(train_accuracy_by_class):\n","        train_class_accuracies[class_names[i]].append(acc)\n","\n","    # Evaluate on validation set\n","    val_loss, val_accuracy, val_accuracy_by_class = evaluate(model, val_loader, classification_criterion, device)\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    for i, acc in enumerate(val_accuracy_by_class):\n","        val_class_accuracies[class_names[i]].append(acc)\n","    \n","    if config[\"scheduler\"] == \"ReduceLR\":\n","        scheduler.step(-val_accuracy)\n","    else:\n","        scheduler.step()\n","\n","    curr_lr = float(optimizer.param_groups[0][\"lr\"])\n","\n","    # train dict\n","    train_acc_dict = {class_name+\"_train_acc\":train_accuracy_by_class[idx] for class_name, idx in DEFECT_CLASSES.items()}\n","    val_acc_dict = {class_name+\"_val_acc\":val_accuracy_by_class[idx] for class_name, idx in DEFECT_CLASSES.items()}\n","    \n","    if USE_WANDB:\n","        wandb.log({\n","            \"train_loss\"       : epoch_loss,\n","            \"train_accuracy\"   : train_accuracy,\n","            \"val_loss\"         : val_loss,\n","            \"val_accuracy\"     : val_accuracy,\n","            \"learning_rate\"    : curr_lr,\n","            **train_acc_dict,\n","            **val_acc_dict,\n","        })\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}] - Training Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n","    print(f\"Epoch [{epoch+1}/{epochs}] - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n","    print(f\"Training Accuracy by Class: {train_accuracy_by_class}\")\n","    print(f\"Validation Accuracy by Class: {val_accuracy_by_class}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":882},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1730484185344,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":240},"id":"9sTzl1MZ5AC2","outputId":"36f3ec43-10af-4ebd-e221-17db41d4e9da"},"outputs":[],"source":["# Plot Training and Validation Loss\n","plt.figure(figsize=(12, 5))\n","plt.plot(range(1, epoch+1), train_losses, label=\"Training Loss\")\n","plt.plot(range(1, epoch+1), val_losses, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.title(\"Training and Validation Loss Over Epochs\")\n","plt.show()\n","\n","# Plot Training and Validation Overall Accuracy\n","plt.figure(figsize=(12, 5))\n","plt.plot(range(1, epoch+1), train_accuracies, label=\"Training Accuracy\")\n","plt.plot(range(1, epoch+1), val_accuracies, label=\"Validation Accuracy\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy (%)\")\n","plt.legend()\n","plt.title(\"Training and Validation Overall Accuracy Over Epochs\")\n","plt.show()\n","\n","# Plot Per-Class Accuracy for Training\n","plt.figure(figsize=(12, 6))\n","for class_name in class_names:\n","    plt.plot(range(1, epoch+1), train_class_accuracies[class_name], label=f\"{class_name} (Train)\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy (%)\")\n","plt.legend()\n","plt.title(\"Per-Class Training Accuracy Over Epochs\")\n","plt.show()\n","\n","# Plot Per-Class Accuracy for Validation\n","plt.figure(figsize=(12, 6))\n","for class_name in class_names:\n","    plt.plot(range(1, epoch+1), val_class_accuracies[class_name], label=f\"{class_name} (Val)\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy (%)\")\n","plt.legend()\n","plt.title(\"Per-Class Validation Accuracy Over Epochs\")\n","plt.show()"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"BbwI5JC244UL"},"outputs":[],"source":["def test(model, test_loader, device, num_classes=6):\n","    \"\"\"\n","    Evaluates the model on the test set, showing a progress bar and returning overall and per-class accuracy and loss.\n","    \"\"\"\n","    class_names = [\"Mouse Bites\", \"Shorts\", \"Open Circuits\", \"Spurs\", \"Missing Holes\", \"Spurious Coppers\"]\n","    model.eval()\n","    running_loss = 0.0\n","    correct = [0] * num_classes\n","    total = [0] * num_classes\n","    class_losses = [0.0] * num_classes  # Store cumulative loss for each class\n","    overall_correct = 0\n","    overall_total = 0\n","    criterion = nn.CrossEntropyLoss(reduction='none')  # Use non-reduced loss for per-class calculation\n","\n","    # Initialize progress bar\n","    with torch.no_grad():\n","        progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n","        for imgs, labels in progress_bar:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)  # Calculate loss for each sample\n","\n","            # Accumulate overall loss\n","            running_loss += loss.sum().item()  # Total loss over all samples\n","\n","            # Calculate overall correct predictions\n","            preds = outputs.argmax(dim=1)\n","            overall_correct += (preds == labels).sum().item()\n","            overall_total += labels.size(0)\n","\n","            # Calculate per-class correct predictions and accumulate per-class loss\n","            for label in range(num_classes):\n","                class_mask = (labels == label)  # Mask for samples of the current class\n","                correct[label] += ((preds == label) & class_mask).sum().item()\n","                total[label] += class_mask.sum().item()\n","\n","                # Calculate per-class loss by summing the loss for the samples of this class\n","                class_losses[label] += loss[class_mask].sum().item()\n","\n","            # Update progress bar with overall loss and accuracy\n","            current_loss = running_loss / overall_total if overall_total > 0 else 0\n","            current_accuracy = 100 * overall_correct / overall_total if overall_total > 0 else 0\n","            progress_bar.set_postfix(loss=current_loss, accuracy=f\"{current_accuracy:.2f}%\")\n","\n","    # Calculate average losses and final metrics\n","    overall_loss = running_loss / overall_total if overall_total > 0 else 0\n","    overall_accuracy = 100 * overall_correct / overall_total if overall_total > 0 else 0\n","    per_class_accuracy = [100 * correct[i] / total[i] if total[i] > 0 else 0 for i in range(num_classes)]\n","    per_class_loss = [class_losses[i] / total[i] if total[i] > 0 else 0 for i in range(num_classes)]\n","\n","    print(f\"Overall Test Loss: {overall_loss:.4f}\")\n","    print(f\"Overall Test Accuracy: {overall_accuracy:.2f}%\")\n","    print(\"\\nPer-Class Results:\")\n","    for i in range(num_classes):\n","        print(f\"{class_names[i]} - Accuracy: {per_class_accuracy[i]:.2f}%, Loss: {per_class_loss[i]:.4f}\")\n","\n","    return overall_loss, overall_accuracy, per_class_accuracy, per_class_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29378,"status":"ok","timestamp":1730486003879,"user":{"displayName":"sungmyeon park","userId":"03642143081403204167"},"user_tz":240},"id":"p4GOXP1Y7wEP","outputId":"f67b707e-6407-4fa0-f513-6c340e30e81d"},"outputs":[],"source":["# Test the model and display results\n","test_loss, test_accuracy, test_per_class_accuracy, test_per_class_loss = test(model, test_loader, device)\n","\n","# Define the class names corresponding to the defect types\n","class_names = [\"Mouse Bites\", \"Shorts\", \"Open Circuits\", \"Spurs\", \"Missing Holes\", \"Spurious Coppers\"]\n","\n","# Plot Per-Class Test Accuracy\n","plt.figure(figsize=(8, 6))\n","bars = plt.bar(class_names, test_per_class_accuracy, color='skyblue')\n","# Add data labels on top of each bar\n","for bar in bars:\n","    height = bar.get_height()\n","    plt.text(\n","        bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n","        height,                             # Y-coordinate (top of the bar)\n","        f'{height:.2f}',                    # Text to display (formatted to 2 decimal places)\n","        ha='center',                        # Horizontal alignment\n","        va='bottom'                         # Vertical alignment\n","    )\n","# Add labels and title\n","plt.xlabel(\"Classes\")\n","plt.ylabel(\"Accuracy (%)\")\n","plt.title(\"Per-Class Test Accuracy\")\n","plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n","plt.tight_layout()  # Adjust layout to fit rotated labels\n","plt.show()\n","\n","# Plot Per-Class Test Loss\n","plt.figure(figsize=(8, 6))\n","bars = plt.bar(class_names, test_per_class_loss, color='salmon')\n","\n","# Add data labels on top of each bar\n","for bar in bars:\n","    height = bar.get_height()\n","    plt.text(\n","        bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n","        height,                             # Y-coordinate (top of the bar)\n","        f'{height:.2f}',                    # Text to display (formatted to 2 decimal places)\n","        ha='center',                        # Horizontal alignment\n","        va='bottom'                         # Vertical alignment\n","    )\n","\n","# Add labels and title\n","plt.xlabel(\"Classes\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Per-Class Test Loss\")\n","plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n","plt.tight_layout()  # Adjust layout to fit rotated labels\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1m8eeR4lndq220jWi-v-x9DtIZRCJN0JX","timestamp":1730762025283},{"file_id":"1t1BbkgxU94ARGMyUT7b3MmHYgD_V8qUX","timestamp":1730470271495}]},"kernelspec":{"display_name":"idl2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.20"}},"nbformat":4,"nbformat_minor":0}
